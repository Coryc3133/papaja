@Article{moors_unconscious_2019,
  title = {Unconscious arithmetic: {Assessing} the robustness of the results reported by {Karpinski}, {Briggs}, and {Yale} (2018)},
  volume = {68},
  issn = {10538100},
  shorttitle = {Unconscious arithmetic},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053810018302848},
  doi = {10.1016/j.concog.2019.01.003},
  language = {en},
  urldate = {2019-01-21TZ},
  journal = {Consciousness and Cognition},
  author = {Pieter Moors and Guido Hesselmann},
  month = {feb},
  year = {2019},
  note = {https://osf.io/cybfe/},
  pages = {97--106},
}

@Article{bol_understanding_2018,
  title = {Understanding the {Effects} of {Personalization} as a {Privacy} {Calculus}: {Analyzing} {Self}-{Disclosure} {Across} {Health}, {News}, and {Commerce} {Contexts}†},
  volume = {23},
  issn = {1083-6101},
  shorttitle = {Understanding the {Effects} of {Personalization} as a {Privacy} {Calculus}},
  url = {https://academic.oup.com/jcmc/article/23/6/370/5140170},
  doi = {10/gftcm6},
  language = {en},
  number = {6},
  urldate = {2019-01-13TZ},
  journal = {Journal of Computer-Mediated Communication},
  author = {Nadine Bol and Tobias Dienlin and Sanne Kruikemeier and Marijn Sax and Sophie C Boerman and Joanna Strycharz and Natali Helberger and Claes H {de Vreese}},
  month = {nov},
  year = {2018},
  note = {},
  pages = {370--388},
}

@Article{peterka-bonetta_relationship_2019,
  title = {The relationship between {Internet} {Use} {Disorder}, depression and burnout among {Chinese} and {German} college students},
  volume = {89},
  issn = {03064603},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0306460318303162},
  doi = {10/gd4rcw},
  language = {en},
  urldate = {2018-12-30TZ},
  journal = {Addictive Behaviors},
  author = {Jessica Peterka-Bonetta and Cornelia Sindermann and Peng Sha and Min Zhou and Christian Montag},
  month = {feb},
  year = {2019},
  note = {},
  pages = {188--199},
}

@Article{heycke_no_2018,
  title = {No evaluative conditioning effects with briefly presented stimuli},
  issn = {0340-0727, 1430-2772},
  url = {http://link.springer.com/10.1007/s00426-018-1109-1},
  doi = {10.1007/s00426-018-1109-1},
  language = {en},
  urldate = {2018-12-03TZ},
  journal = {Psychological Research},
  author = {Tobias Heycke and Christoph Stahl},
  month = {oct},
  year = {2018},
  note = {},
}

@Article{heycke_two_2018,
  title = {Of two minds or one? {A} registered replication of {Rydell} et al. (2006)},
  volume = {32},
  issn = {0269-9931, 1464-0600},
  shorttitle = {Of two minds or one?},
  url = {https://www.tandfonline.com/doi/full/10.1080/02699931.2018.1429389},
  doi = {10.1080/02699931.2018.1429389},
  language = {en},
  number = {8},
  urldate = {2018-12-03TZ},
  journal = {Cognition and Emotion},
  author = {Tobias Heycke and Sarah Gehrmann and Julia M. Haaf and Christoph Stahl},
  month = {nov},
  year = {2018},
  pages = {1708--1727},
  note = {},
}

@Article{rouder_minimizing_2018,
  title = {Minimizing {Mistakes} {In} {Psychological} {Science}},
  url = {https://osf.io/gxcy5},
  doi = {10/gfdb27},
  abstract = {Developing and implementing best practices in organizing a lab is challenging, especially in the face of new cultural norms such as the open-science movement.  Part of this challenge in today's landscape is using new technologies such as cloud storage and computer automation.  Here we discuss a few practices designed to increase the reliability of scientific labs by focusing on what technologies and elements minimize common, ordinary mistakes.  We borrow principles from the Theory of High-Reliability Organizations which has been used to characterize operational practices in high-risk environments such as aviation and healthcare.  From these principles, we focus on five elements: 1. implementing a lab culture focused on learning from mistakes; 2. using computer automation in data and meta-data collection wherever possible; 3. standardizing organization strategies; 4. using coded rather than menu-driven analyses; 5. developing expanded documents that record how analyses were performed.},
  urldate = {2018-10-23TZ},
  journal = {PsyArXiv},
  author = {Jeffrey Rouder and Julia M. Haaf and Hope K. Snyder},
  month = {jun},
  year = {2018},
  note = {https://github.com/PerceptionAndCognitionLab/lab-transparent},
}

@Article{haaf_and_2018,
  title = {Some do and some don’t? {Accounting} for variability of individual difference structures.},
  shorttitle = {Some do and some don’t?},
  url = {https://osf.io/zwjtp},
  doi = {10.31234/osf.io/zwjtp},
  abstract = {A prevailing notion in experimental psychology is that individuals' performance in a task varies gradually in a continuous fashion. In a Stroop task, for example, the true average effect may be 50ms with a standard deviation of say 30ms. In this case, some individuals will have greater effects than 50ms, some will have smaller, and some are fore-casted to have negative effects in sign - they respond faster to incongruent items than to congruent ones!  But are there people who have a true negative effect in Stroop or any other task?  We highlight three *qualitatively different* effects: negative effects, null effects, and positive effects.  The main goal of this paper is to develop models that allow researchers to explore whether all three are present in a task: Do all individuals show a positive effect? Are there individuals with truly no effect?  Are there any individuals with negative effects?  We develop a family of Bayesian hierarchical models that capture a variety of these constraints. We apply this approach to Stroop interference experiments and a near-liminal priming experiment where the prime may be below and above threshold for different people.  We show that most tasks people are quite alike - for example everyone has positive Stroop effects and nobody fails to Stroop or Stroops negatively.  We also show a case that under very specific circumstances,  we could entice some people to not Stroop at all.},
  urldate = {2018-10-23TZ},
  journal = {PsyArXiv},
  author = {Julia M. Haaf and Jeffrey Rouder},
  month = {aug},
  year = {2018},
  note = {https://github.com/PerceptionAndCognitionLab/ctx-mixture},
}

@Article{haaf_note_2018,
  title = {A {Note} on {Using} {Systems} of {Orders} to {Capture} {Theoretical} {Constraint} in {Psychological} {Science}},
  url = {https://osf.io/a4xu9},
  doi = {10/gffjrf},
  abstract = {Most theories in the social sciences are verbal and provide ordinal-level predictions for data. For example, a theory might predict that performance is better in one condition than another, but not by how much. One way of gaining additional specificity is to posit multiple ordinal constraints simultaneously. For example a theory might predict an effect in one condition, a larger effect in another, and none in a third. We call such simultaneous constraints a ‘system of orders’ and show how common theoretical positions lead naturally to system-of-order predictions. We adopt a Bayesian model comparison approach to assess evidence for multiple, simultaneous order constraints, a difficult endeavor in a frequentist framework. The result is a statistical system custom tuned for the way social scientists conceptualize theory that is more intuitive and informative than current linear-model approaches.},
  urldate = {2018-10-23TZ},
  journal = {PsyArXiv},
  author = {Julia M. Haaf and Fayette Klaassen and Jeffrey Rouder},
  month = {mar},
  year = {2018},
  note = {https://github.com/PerceptionAndCognitionLab/bf-order},
}

@Article{bergmann_promoting_2018,
  title = {Promoting {Replicability} in {Developmental} {Research} {Through} {Meta}-analyses: {Insights} {From} {Language} {Acquisition} {Research}},
  issn = {00093920},
  shorttitle = {Promoting {Replicability} in {Developmental} {Research} {Through} {Meta}-analyses},
  url = {http://doi.wiley.com/10.1111/cdev.13079},
  doi = {10.1111/cdev.13079},
  language = {en},
  urldate = {2018-05-25TZ},
  journal = {Child Development},
  author = {Christina Bergmann and Sho Tsuji and Page E. Piccinini and Molly L. Lewis and Mika Braginsky and Michael C. Frank and Alejandrina Cristia},
  month = {may},
  year = {2018},
  note = {https://osf.io/uhv3d/},
}

@Article{rouder_beyond_2017,
  title = {Beyond {Overall} {Effects}: {A} {Bayesian} {Approach} to {Finding} {Constraints} {Across} {A} {Collection} {Of} {Studies} {In} {Meta}-{Analysis}},
  shorttitle = {Beyond {Overall} {Effects}},
  url = {https://osf.io/zubr3},
  doi = {10/gffjrd},
  abstract = {Most meta-analyses focus on meta-analytic means, testing whether they are significantly different from zero and how they depend on covariates.  This mean is difficult to defend as a construct because the underlying distribution of studies reflects many factors such as how we choose to run experiments.  We argue that the fundamental questions of meta-analysis should not be about the aggregated mean; instead, one should ask which relations are stable across all the studies.  In a typical meta-analysis, there is a preferred or hypothesized direction (e.g., that violent video games increase, rather than decrease, agressive behavior).  We ask whether all studies in a meta-analysis have true effects in a common direction. If so, this is an example of a stable relation across all the studies.  We propose four models: (i) all studies are truly null; (ii) all studies share a single true nonzero effect; (iii) studies differ, but all true effects are in the same direction; and (iv) some study effects are truly positive while others are truly negative.  We develop Bayes factor model comparison for these models and apply them to four extant meta-analyses to show their usefulness.},
  urldate = {2018-10-23TZ},
  journal = {PsyArXiv},
  author = {Jeffrey Rouder and Julia M. Haaf and Clintin Stober and Joseph Hilgard},
  month = {oct},
  year = {2017},
  note = {https://github.com/PerceptionAndCognitionLab/meta-planned},
}

@Article{lewis_quantitative_2017,
  title = {A {Quantitative} {Synthesis} of {Early} {Language} {Acquisition} {Using} {Meta}-{Analysis}},
  url = {https://osf.io/htsjm},
  doi = {10.31234/osf.io/htsjm},
  abstract = {To acquire a language, children must learn a range of skills, from the sounds of their language to the meanings of words. These skills are typically studied in isolation in separate research programs, but there is a growing body of evidence that these skills may depend on each other in acquisition (e.g., Feldman, Myers, White, Griffiths, \&amp; Morgan, 2013; Johnson, Demuth, Jones, \&amp; Black, 2010; Shukla, White, \&amp; Aslin, 2011). We suggest that the meta-analytic method can support the process of building theories that take a systems-level perspective, as well as provide a tool for detecting bias in a literature. Here we present meta-analyses of 12 phenomena in language acquisition, with over 800 effect sizes. We find that the language acquisition literature overall has a high degree of evidential value. We then present a quantitative synthesis of language acquisition phenomena that suggests interactivity across the system.},
  urldate = {2018-10-23TZ},
  journal = {PsyArXiv},
  author = {Molly Lewis and Mika Braginsky and Sho Tsuji and Christina Bergmann and Page Elizabeth Piccinini and Alejandrina Cristia and Michael C. Frank},
  month = {oct},
  year = {2017},
  note = {},
}

@Article{flygare_adapted_2018,
  title = {Adapted cognitive behavior therapy for obsessive compulsive disorder with co-occuring autism spectrum disorder: {A} clinical effectiveness study},
  shorttitle = {Adapted cognitive behavior therapy for obsessive compulsive disorder with co-occuring autism spectrum disorder},
  url = {https://osf.io/fy6s4},
  doi = {10/gffjrb},
  abstract = {Obsessive-compulsive disorder (OCD) and autism spectrum disorder (ASD) commonly co-occur. Adapted CBT for OCD in adults with ASD has not previously been evaluated outside the United Kingdom. In this study, 19 adults with OCD and Asperger syndrome were treated using an updated CBT protocol. The primary outcome was the Yale-Brown Obsessive-Compulsive Scale (YBOCS). Secondary outcomes were self-rated obsessive-compulsive symptoms, depressive symptoms, quality of life, and daily functioning. Participants were assessed at baseline, at 10 weeks during treatment, at post-treatment and at 3-month follow-up. Treatment response and remission were determined according to international consensus definitions. There were large reductions on the YBOCS at post-treatment, and improvements were sustained at follow-up (d=1.2). Self-rated OCD symptoms and depressive symptoms also showed statistically significant reductions. Improvements in general functioning and quality of life were non-significant. At follow-up, three participants were responders and one was in full remission. Adapted CBT for OCD in adults with co-occuring ASD is associated with significant reductions in obsessive-compulsive symptoms and depressive symptoms. However, outcomes were modest; few patients were completely symptom free, and general functioning and quality of life did not improve significantly. We identify and discuss the need for further treatment refinement for this vulnerable patient group.},
  urldate = {2018-10-23TZ},
  journal = {PsyArXiv},
  author = {Oskar Flygare and Erik Andersson and Helene Ringberg and Anna-Clara Hellstadius and Johan Edbacken and Jesper Enander and Matti Dahl and Kristina Aspvall and Indra Windh and Ailsa J Russell and David Mataix-Cols and Christian R{\"u}ck},
  month = {oct},
  year = {2018},
  note = {https://osf.io/gj87z/},
}

@Article{rouder_psychometrics_2018,
  title = {A {Psychometrics} of {Individual} {Differences} in {Experimental} {Tasks}},
  url = {https://osf.io/f3h2k},
  doi = {10/gfdbw2},
  abstract = {In modern individual-difference studies, researchers often correlate performance on various tasks to uncover common latent processes.  Yet, in some sense, the results have been disappointing as correlations among tasks that seemingly have processes in common are often low.   A pressing question then is whether these attenuated correlations reflect statistical considerations, such as a lack of individual variability on tasks, or substantive considerations, such as that inhibition in different tasks is not a unified concept.  One problem in addressing this question is that researchers aggregate performance across trials to tally individual-by-task scores, and the covariation of these scores is subsequently studied much as it would be with classical test theory.  It is tempting to think that aggregation here is fine and everything comes out in the wash, but as shown here, it greately attenuates measures of effect size and correlation.  We propose an alternative psychometrics of task performance that is based on accounting for trial-by-trial variability along with the covariation of individuals' performance across tasks.  The implementation is through common hierarchical models, and this treatment rescues classical concepts of effect size, reliability, and correlation for studying individual differences with experimental tasks.  Using recent data from Hedge et al. (2018) we show  that there is Bayes-factor support for a lack of correlation between the Stroop and flanker task.  This support for a lack of correlation indicates a psychologically relevant result---Stroop and flanker inhibition are seemingly unrelated, contradicting unified concepts of inhibition.},
  urldate = {2018-10-23TZ},
  journal = {PsyArXiv},
  author = {Jeffrey Rouder and Julia M. Haaf},
  month = {aug},
  year = {2018},
  note = {https://github.com/PerceptionAndCognitionLab/ctx-reliability},
}

@Article{robison_pupillometry_2018,
  title = {Pupillometry tracks fluctuations in working memory performance},
  url = {https://osf.io/5a7ck},
  doi = {10/gdz63r},
  abstract = {In 3 experiments, we examined fluctuations in working memory (WM) performance and associated changes in pretrial and task-evoked pupil diameter. Additionally, we examined whether behavioral lapses were accompanied by self-reports of off-task attentional states. The results demonstrated that task-evoked pupillary responses can be used to measure moment-to-moment fluctuations in the success of WM maintenance during delay intervals. Further, when individuals reported being in an off-task attentional state, their WM performance suffered. Additionally, when probed directly after a particularly poor trial, participants reported being in an off-task attentional state more often than at random intervals throughout the task. So behavioral, subjective, and physiological data converged when people experienced WM failures. Although pretrial pupil diameter did not consistently differentiate between successful and unsuccessful trials, variability in pretrial pupil diameter accounted for a significant portion of variance in WM task performance. This effect persisted after controlling for mean task-evoked pupillary response and variability in task-evoked pupillary responses. Thus, one of the major reasons people varied in the consistency with which they utilized their WM system was variability in arousal. Such variability in arousal is potentially due to variation in the functioning of the LC-NE neuromodulatory system, and thus may underlie individual differences in WM capacity and attention control.},
  urldate = {2018-08-16TZ},
  journal = {PsyArXiv},
  author = {Matthew Kyle Robison and Nash Unsworth},
  year = {2018},
  note = {osf.io/vuw9h/},
}

@Article{hardwicke_data_2018,
  title = {Data availability, reusability, and analytic reproducibility: evaluating the impact of a mandatory open data policy at the journal \textit{{Cognition}}},
  volume = {5},
  issn = {2054-5703},
  shorttitle = {Data availability, reusability, and analytic reproducibility},
  url = {http://rsos.royalsocietypublishing.org/lookup/doi/10.1098/rsos.180448},
  doi = {10/gdz63s},
  abstract = {Access to data is a critical feature of an efficient, progressive and ultimately self-correcting scientific ecosystem. But the extent to which in-principle benefits of data sharing are realized in practice is unclear. Crucially, it is largely unknown whether published findings can be reproduced by repeating reported analyses upon shared data (‘analytic reproducibility’). To investigate this, we conducted an observational evaluation of a mandatory open data policy introduced at the journal Cognition. Interrupted time-series analyses indicated a substantial post-policy increase in data available statements (104/417, 25\% pre-policy to 136/174, 78\% post-policy), although not all data appeared reusable (23/104, 22\% pre-policy to 85/136, 62\%, post-policy). For 35 of the articles determined to have reusable data, we attempted to reproduce 1324 target values. Ultimately, 64 values could not be reproduced within a 10\% margin of error. For 22 articles all target values were reproduced, but 11 of these required author assistance. For 13 articles at least one value could not be reproduced despite author assistance. Importantly, there were no clear indications that original conclusions were seriously impacted. Mandatory open data policies can increase the frequency and quality of data sharing. However, suboptimal data curation, unclear analysis specification and reporting errors can impede analytic reproducibility, undermining the utility of data sharing and the credibility of scientific findings.},
  language = {en},
  number = {8},
  urldate = {2018-08-16TZ},
  journal = {Royal Society Open Science},
  author = {Tom E. Hardwicke and Maya B. Mathur and Kyle MacDonald and Gustav Nilsonne and George C. Banks and Mallory C. Kidwell and Alicia {Hofelich Mohr} and Elizabeth Clayton and Erica J. Yoon and Michael {Henry Tessler} and Richie L. Lenne and Sara Altman and Bria Long and Michael C. Frank},
  month = {aug},
  year = {2018},
  note = {https://osf.io/wn8fd/},
  pages = {180448},
}

@Article{vuorre_curating_2018,
  title = {Curating {Research} {Assets}: {A} {Tutorial} on the {Git} {Version} {Control} {System}},
  shorttitle = {Curating {Research} {Assets}},
  url = {https://osf.io/6tzh8},
  doi = {10.31234/osf.io/6tzh8},
  abstract = {Recent calls for improving reproducibility have increased attention to the ways in which researchers curate, share and collaborate on their research assets. In this tutorial paper, we explain how version control systems, such as the popular Git program, address these challenges to reproducibility. We then present a tutorial on how to use Git with a graphical interface in the R Studio program. This tutorial is written for researchers with no previous experience using version control systems, and covers single-user and collaborative workflows. An online supplement provides information on advanced Git command line functions. Git presents an elegant solution to specific challenges to reproducibility, facilitates multi-site collaboration and productivity by allowing multiple collaborators to work on the same source files simultaneously, and can be implemented to common workflows with little extra effort. Git may also offer a suitable solution to transparent data and material sharing through popular online services, such as GitHub and Open Science Framework.},
  urldate = {2018-08-13TZ},
  journal = {PsyArXiv},
  author = {Matti Vuorre and James P. Curley},
  year = {2018},
  note = {https://github.com/mvuorre/reproguide-curate},
}

@Article{faulkenberry_task_2018,
  title = {Task instructions modulate unit–decade binding in two-digit number representation},
  issn = {0340-0727, 1430-2772},
  url = {http://link.springer.com/10.1007/s00426-018-1057-9},
  doi = {10/gdxv8k},
  language = {en},
  urldate = {2018-08-08TZ},
  journal = {Psychological Research},
  author = {Thomas J. Faulkenberry and Alexander Cruise and Samuel Shaki},
  month = {jul},
  year = {2018},
  note = {https://github.com/tomfaulkenberry/twoDigitTaskManip},
}

@Article{barth_assumptions_2018,
  title = {Assumptions of the process-dissociation procedure are violated in implicit sequence learning.},
  issn = {1939-1285, 0278-7393},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/xlm0000614},
  doi = {10/gdxv8m},
  language = {en},
  urldate = {2018-08-08TZ},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  author = {Marius Barth and Christoph Stahl and Hilde Haider},
  month = {jul},
  year = {2018},
  note = {https://github.com/methexp/pdl2},
}

@Article{aust_memory-based_2018,
  title = {A memory-based judgment account of expectancy-liking dissociations in evaluative conditioning.},
  issn = {1939-1285, 0278-7393},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/xlm0000600},
  doi = {10/gdxv8n},
  language = {en},
  urldate = {2018-08-08TZ},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  author = {Frederik Aust and Julia M. Haaf and Christoph Stahl},
  month = {jul},
  year = {2018},
  note = {https://osf.io/vnmby/},
}

@Article{lakens_equivalence_2018,
  title = {Equivalence {Testing} for {Psychological} {Research}: {A} {Tutorial}},
  volume = {1},
  issn = {2515-2459, 2515-2467},
  shorttitle = {Equivalence {Testing} for {Psychological} {Research}},
  url = {http://journals.sagepub.com/doi/10.1177/2515245918770963},
  doi = {10/gdj7s9},
  language = {en},
  number = {2},
  urldate = {2018-08-08TZ},
  journal = {Advances in Methods and Practices in Psychological Science},
  author = {Dani{\"e}l Lakens and Anne M. Scheel and Peder M. Isager},
  month = {jun},
  year = {2018},
  note = {https://osf.io/qamc6/},
  pages = {259--269},
}

@Article{maxwell_modeling_2018,
  title = {Modeling {Memory}: {Exploring} the {Relationship} {Between} {Word} {Overlap} and {Single} {Word} {Norms} when {Predicting} {Relatedness} {Judgments} and {Retrieval}},
  shorttitle = {Modeling {Memory}},
  url = {https://osf.io/qekad/},
  doi = {10.17605/osf.io/qekad},
  abstract = {This study examined the interactive relationship between semantic, thematic, and associative word pair strength in the prediction of item relatedness judgments and cued-recall performance. Previously, we found significant three-way interactions between associative, semantic, thematic word overlap when predicting participant judgment strength and recall performance (Maxwell \& Buchanan, 2018), expanding upon previous work by Maki (2007). In this study, we first seek to replicate findings from the original study using a novel stimuli set. Second, this study will further explore the nature of the structure of memory, by investigating the effects of single concept information (i.e., word frequency, concreteness, etc.) on relatedness judgments and recall accuracy. We hypothesize that associative, semantic, and thematic memory networks are interactive in their relationship to judgments and recall, even after controlling for base rates of single concept information, implying a set of interdependent memory systems used for both cognitive processes.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Nicholas Maxwell and Erin Buchanan},
  month = {jul},
  year = {2018},
  note = {https://osf.io/j7qtc/},
}

@Article{craddock_transcranial_2018,
  title = {Transcranial alternating current stimulation at 10 {Hz} modulates response bias in the {Somatic} {Signal} {Detection} {Task}},
  url = {http://biorxiv.org/lookup/doi/10.1101/330134},
  doi = {10.1101/330134},
  abstract = {Background: Ongoing, pre-stimulus oscillatory activity in the 8-13 Hz alpha range has been shown to correlate with both true and false reports of peri-threshold somatosensory stimuli. However, to directly test the role of such oscillatory activity in behaviour, it is necessary to manipulate it. Transcranial alternating current stimulation (tACS) offers a method of directly manipulating oscillatory brain activity using a sinusoidal current passed to the scalp.
Objective: We tested whether alpha tACS would change somatosensory sensitivity or response bias in a signal detection task in order to test whether alpha oscillations have a causal role in behaviour.
Methods: Active 10 Hz tACS or sham stimulation was applied using electrodes placed bilaterally at positions CP3 and CP4 of the 10-20 electrode placement system. Participants performed the Somatic Signal Detection Task (SSDT), in which they must detect brief somatosensory targets delivered at their detection threshold. These targets are sometimes accompanied by a light flash, which could also occur alone. 
Results: Active tACS did not modulate sensitivity to targets but did modulate response criterion. Specifically, we found that  active stimulation generally increased touch reporting rates, but particularly increased responding on light trials. Stimulation did not interact with the presence of touch, and thus increased both hits and false alarms. 
Conclusions: tACS stimulation increased reports of touch in a manner consistent with our observational reports, changing response bias, and consistent with a role for alpha activity in somatosensory detection.},
  urldate = {2018-06-06TZ},
  journal = {bioRxiv},
  author = {Matt Craddock and Ekaterini Klepousniotou and Wael El-Deredy and Ellen Poliakoff and Donna M. Lloyd},
  year = {2018},
  note = {},
}

@Article{buchanan_n400s_2018,
  title = {The {N}400's 3 {As}: {Association}, {Automaticity}, {Attenuation} (and {Some} {Semantics} {Too})},
  shorttitle = {The {N}400's 3 {As}},
  url = {https://osf.io/6w2se/},
  doi = {10.17605/osf.io/6w2se},
  abstract = {The N400 waveform carries new insight into the nature of linguistic processing and may shed light into the automaticity of priming word relationships. We investigated semantic and associative word pairs in classic lexical decision and letter search tasks to examine their differences in cognitive processing. Normed database information was used to create orthogonal semantic and associative word relationships to clearly define N400 waveforms and priming for these pairs. Participants showed N400 reduction for related word pairs, both semantic and associative, in comparison to unrelated word pairs for the lexical decision task, indicating automatic access for both types of relatedness. For a letter search task, the N400 showed differences between nonwords and other stimuli but no attenuation for related pairs. Response latency data indicated associative priming in both tasks with semantic priming also found in the letter search task. These results help discern possible automatic and controlled processes occurring during these tasks, as the N400 may show automatic processing during the lexical decision task, while the response latency data may provide evidence for controlled processing during the letter search task.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Erin Buchanan and John Scofield and Nathan Nunley},
  year = {2018},
  note = {https://osf.io/h5sd6/},
}

@Article{buchanan_lab:_2018,
  title = {The {LAB}: {Linguistic} {Annotated} {Bibliography}},
  shorttitle = {The {LAB}},
  url = {https://osf.io/h3bwx/},
  doi = {10.17605/osf.io/h3bwx},
  abstract = {In the era of big data, psycholinguistic research is flourishing with numerous publications that advance our knowledge of concept characteristics and ways to study them. This article presents the Linguistic Annotated Bibliography (LAB) as a searchable web portal to quickly and easily access reliable database norms, related programs, and variable calculations. These publications (*N* = 706) were coded by language, number of stimuli, stimuli type (i.e., words, pictures, symbols), keywords (i.e., frequency, semantics, valence), and other useful information. This tool not only allows researchers to search for the specific type of stimuli needed for experiments, but also permits the exploration of publication trends across 100 years of research. Details about the portal creation and use are outlined, as well as various analyses of change in publication rates and keywords. In general, advances in computation power have allowed for the increase in dataset size in the recent decades, in addition to an increase in the number of linguistic variables provided in each publication.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Erin Buchanan and Kathrene Valentine and Nicholas Maxwell},
  year = {2018},
  note = {https://osf.io/9bcws/},
}

@Article{heycke_subliminal_2017,
  title = {Subliminal influence on preferences? {A} test of evaluative conditioning for brief visual conditioned stimuli using auditory unconditioned stimuli},
  volume = {4},
  copyright = {© 2017 The Authors.. Published by the Royal Society under the terms of the Creative Commons Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use, provided the original author and source are credited.},
  issn = {2054-5703},
  shorttitle = {Subliminal influence on preferences?},
  url = {http://rsos.royalsocietypublishing.org/content/4/9/160935},
  doi = {10.1098/rsos.160935},
  abstract = {In the field of evaluative conditioning (EC), two opposing theories—propositional single-process theory versus dual-process theory—are currently being discussed in the literature. The present set of experiments test a crucial prediction to adjudicate between these two theories: Dual-process theory postulates that evaluative conditioning can occur without awareness of the contingency between conditioned stimulus (CS) and unconditioned stimulus (US); in contrast, single-process propositional theory postulates that EC requires CS-US contingency awareness. In a set of three studies, we experimentally manipulate contingency awareness by presenting the CSs very briefly, thereby rendering it unlikely to be processed consciously. We address potential issues with previous studies on EC with subliminal or near-threshold CSs that limited their interpretation. Across two experiments, we consistently found an EC effect for CSs presented for 1000 ms and consistently failed to find an EC effect for briefly presented CSs. In a third pre-registered experiment, we again found evidence for an EC effect with CSs presented for 1000 ms, and we found some indication for an EC effect for CSs presented for 20 ms.},
  language = {en},
  number = {9},
  urldate = {2017-10-20TZ},
  journal = {Royal Society Open Science},
  author = {Tobias Heycke and Frederik Aust and Christoph Stahl},
  month = {sep},
  year = {2017},
  pages = {160935},
  note = {},
}

@Article{stahl_subliminal_2016,
  title = {Subliminal {Evaluative} {Conditioning}? {Above}-{Chance} {CS} {Identification} {May} {Be} {Necessary} and {Insufficient} for {Attitude} {Learning}},
  volume = {145},
  issn = {0096-3445},
  shorttitle = {Subliminal {Evaluative} {Conditioning}?},
  url = {http://search.ebscohost.com/login.aspx?direct=true&db=pdh&AN=2016-31412-001&site=ehost-live},
  doi = {10.1037/xge0000191},
  abstract = {Previous research has claimed that evaluative conditioning (EC) effects may obtain in the absence of perceptual identification of conditioned stimuli (CSs). A recent meta-analysis suggested similar effect sizes for supra- and subliminal CSs, but this was based on a small body of evidence (k = 8 studies; Hofmann, De Houwer, Perugini, Baeyens, \& Crombez, 2010). We critically discuss this prior evidence, and then report and discuss 6 experimental studies that investigate EC effects for briefly presented CSs using more stringent methods. Across these studies, we varied CS duration, the presence or absence of masking, the presence or absence of a CS identification check, CS material, and the instructions communicated to participants. EC effects for longer-duration CSs were modulated by attention to the CS–US pairing. Across studies, we were consistently unable to obtain EC for briefly presented CSs. In most studies, this pattern was observed despite above-chance perceptual identification of the CSs. A meta-analysis conducted across the 27 experimental conditions supported the null hypothesis of no EC for perceptually unidentified CSs. We conclude that EC effects for briefly presented and masked CSs are either not robust, are very small, or are limited to specific conditions that remain to be identified (or any combination of these). (PsycINFO Database Record (c) 2016 APA, all rights reserved). (journal abstract)},
  urldate = {2016-06-28TZ},
  journal = {Journal of Experimental Psychology: General},
  author = {Christoph Stahl and Julia Haaf and Olivier Corneille},
  year = {2016},
  pages = {1107--1131},
  note = {},
}

@Article{papenberg_sequentially_2017,
  title = {Sequentially presented response options prevent the use of testwiseness cues in multiple-choice testing},
  volume = {59},
  url = {http://www.psychologie-aktuell.com/fileadmin/download/ptam/2-2017_20170627/06_Papenberg_.pdf},
  language = {en},
  number = {2},
  journal = {Psychological Test and Assessment Modeling},
  author = {Martin Papenberg and Sonja Willing and Jochen Musch},
  year = {2017},
  keywords = {🔍No DOI found},
  pages = {245--266},
  note = {},
}

@Article{mchugh_searching_2017,
  title = {Searching for {Moral} {Dumbfounding}: {Identifying} {Measurable} {Indicators} of {Moral} {Dumbfounding}},
  volume = {3},
  issn = {2474-7394},
  shorttitle = {Searching for {Moral} {Dumbfounding}},
  url = {http://www.collabra.org/article/10.1525/collabra.79/},
  doi = {10.1525/collabra.79},
  number = {1},
  urldate = {2018-05-25TZ},
  journal = {Collabra: Psychology},
  author = {Cillian McHugh and Marek McGann and Eric R. Igou and Elaine L. Kinsella},
  month = {oct},
  year = {2017},
  note = {https://osf.io/wm6vc/},
}

@Article{buchanan_perceived_2018,
  title = {Perceived {Grading} and {Student} {Evaluation} of {Instruction}},
  url = {https://osf.io/7x4uf/},
  doi = {10.17605/osf.io/7x4uf},
  abstract = {We analyzed student evaluations for 3,585 classes collected over 20 years to determine stability and evaluate the relationship of perceived grading to global evaluations, perceived fairness, and appropriateness of assignments. Using class as the unit of analysis, we found small evaluation reliability when professors taught the same course in the same semester, with much weaker correlations for differing courses. Expected grade and grading related questions correlated with overall evaluations of courses. Differences in course evaluations on expected grades, grading questions, and overall grades were found between full-time faculty and other types of instructors. These findings are expanded to a model of grading type questions mediating the relationship between expected grade and overall course evaluations with a moderating effect of type of instructor.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Erin Buchanan and Becca Johnson and Arden Miller and David Stockburger and Marshall Beauchamp},
  year = {2018},
  note = {https://osf.io/jdpfs/},
}

@Article{sauer_observation_2017,
  title = {Observation oriented modeling revised from a statistical point of view},
  issn = {1554-3528},
  url = {http://link.springer.com/10.3758/s13428-017-0949-8},
  doi = {10.3758/s13428-017-0949-8},
  language = {en},
  urldate = {2018-05-25TZ},
  journal = {Behavior Research Methods},
  author = {Sebastian Sauer},
  month = {aug},
  year = {2017},
  note = {https://osf.io/6vhja/},
}

@Article{buchanan_methods_2018,
  title = {Methods to detect low quality data and its implication for psychological research},
  issn = {1554-3528},
  url = {http://link.springer.com/10.3758/s13428-018-1035-6},
  doi = {10.3758/s13428-018-1035-6},
  language = {en},
  urldate = {2018-05-25TZ},
  journal = {Behavior Research Methods},
  author = {Erin M. Buchanan and John E. Scofield},
  month = {mar},
  year = {2018},
  note = {https://osf.io/x6t8a/},
}

@Article{harms_making_2018,
  title = {Making '{Null} {Effects}' {Informative}: {Statistical} {Techniques} and {Inferential} {Frameworks}},
  shorttitle = {Making '{Null} {Effects}' {Informative}},
  url = {https://psyarxiv.com/48zca/},
  doi = {10.17605/osf.io/48zca},
  abstract = {The investigation of ‘null effects’ is important for cumulative knowledge generation in science. To draw informative conclusions from null-effects, re- searchers need to move beyond the incorrect interpretation of non-significant results in a null-hypothesis significance test as evidence for the absence of an effect. We explain how to statistically evaluate null-results using equiv- alence tests, Bayesian estimation, and Bayes factors. A worked example demonstrates how to apply these statistical tools, and interpret the results. Finally, we explain how no statistical approach can actually prove that the null-hypothesis is true, and briefly discuss the philosophical differences be- tween statistical approaches to examine null-effects. The increasing avail- ability of software and online tools to perform equivalence tests, Bayesian estimation, and Bayes factors make it timely and feasible to move beyond traditional null-hypothesis tests, and allow researchers to draw more infor- mative conclusions about null-effects.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Christopher Harms and Daniel Lakens},
  year = {2018},
  note = {https://osf.io/wptju/},
}

@Article{maxwell_investigating_2018,
  title = {Investigating the {Interaction} between {Associative}, {Semantic}, and {Thematic} {Database} {Norms} for {Memory} {Judgments} and {Retrieval}},
  url = {https://osf.io/fcesn/},
  doi = {10.17605/osf.io/fcesn},
  abstract = {This study examined the interactive relationship between semantic, thematic, and associative word pair strength in the prediction of judgments and cued-recall performance. One hundred and twelve participants were recruited from Amazon's Mechanical Turk. They were shown word pairs of varying relatedness and were then asked to judge these word pairs for their semantic, thematic, and associative strength. After completing a distractor task, participants then completed a cued recall task. The data was then analyzed through multilevel modeling, incorporating a logistic regression to account for the binary nature of the recall.  Four hypotheses were tested. First, we sought to expand previous work on memory judgments to include three types of judgments of memory, while also replicating bias and sensitivity findings. Next, we tested for an interaction between the three database norms (FSG, COS, and LSA) when predicting participant judgments. Third, we extended this analysis to test for interactions between the three database norms when predicting recall. In both our second and third hypothesis, significant three-way interactions were found between FSG, COS, and LSA when predicting judgments or recall. For low semantic feature overlap, thematic and associative strength were competitive; as thematic strength increased, associative predictiveness decreased. However, this trend reversed for high semantic feature overlap, wherein thematic and associative strength were complimentary as both set of simple slopes increased together. Finally, we showed that judgment-database slopes were predictive of recall.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Nicholas Maxwell and Erin Buchanan},
  year = {2018},
  note = {https://osf.io/y8h7v/},
}

@Article{aust_incremental_2016,
  title = {Incremental validity of {Useful} {Field} of {View} subtests for the prediction of instrumental activities of daily living},
  volume = {38},
  issn = {1380-3395, 1744-411X},
  url = {https://www.tandfonline.com/doi/full/10.1080/13803395.2015.1125453},
  doi = {10.1080/13803395.2015.1125453},
  language = {en},
  number = {5},
  urldate = {2018-05-25TZ},
  journal = {Journal of Clinical and Experimental Neuropsychology},
  author = {Frederik Aust and Jerri D. Edwards},
  month = {may},
  year = {2016},
  pages = {497--515},
  note = {},
}

@Article{pollet_how_2018,
  title = {How diverse are the samples used in the journals ‘{Evolution} \& {Human} {Behavior}’ and ‘{Evolutionary} {Psychology}’?},
  url = {https://osf.io/7h24p/},
  doi = {10.17605/osf.io/7h24p},
  abstract = {The psychological literature is regularly criticised on the basis that limited sampling quality might restrict the inferences that can be made. Specifically, researchers have raised concerns regarding over-reliance upon samples from Western Educated Industrialised Rich and Democratic (WEIRD) societies, and in particular from university students. In addition, a growing tendency to collect data using anonymous and unsupervised online surveys might introduce problems of data quality. Studies from evolutionary psychology often seek to uncover aspects of evolved universal characteristics, and so criticisms of sample diversity would be a particular problem for the field. Here, we empirically examine the samples used in the 2015 volumes of ‘Evolution \& Human Behavior’ (57 articles) and ‘Evolutionary Psychology’ (43 articles). Our database consists of 166 samples of humans (median sample size= 206). The majority of samples were either online or student samples (60\% of samples), followed by other adult Western samples (19\%). 129 of the samples were classified as ‘Western’ (78\%, Europe/North America/Australia). The remaining samples were predominantly from Asia (N= 26; 16\%, mostly Japan). Only a small fraction of the samples was classified as cross-cultural (5), South American (3) or African (2). The median sample size did not significantly differ between continents, but online samples (both paid and unpaid) were typically larger than samples sourced offline. While it seems that the samples used are more diverse than those that have been reported in reviews of the literature from social and developmental psychology, it also apparent that the majority of samples remain WEIRD. We discuss the implications for Evolutionary Psychology as a discipline.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Thomas V. Pollet and Tamsin Saxton},
  year = {2018},
  note = {},
}

@Article{beaton_generalization_2018,
  title = {Generalization of the minimum covariance determinant algorithm for categorical and mixed data types},
  url = {http://biorxiv.org/lookup/doi/10.1101/333005},
  doi = {10.1101/333005},
  abstract = {The minimum covariance determinant (MCD) algorithm is one of the most common techniques to detect anomalous or outlying observations. The MCD algorithm depends on two features of multivariate data: the determinant of a matrix (i.e., geometric mean of the eigenvalues) and Mahalanobis distances (MD). While the MCD algorithm is commonly used, and has many extensions, the MCD is limited to analyses of quantitative data and more specifically data assumed to be continuous. One reason why the MCD does not extend to other data types such as categorical or ordinal data is because there is not a well-defined MD for data types other than continuous data. To address the lack of MCD-like techniques for categorical or mixed data we present a generalization of the MCD. To do so, we rely on a multivariate technique called correspondence analysis (CA). Through CA we can define MD via singular vectors and we can compute the determinant from CA's eigenvalues. Here we define and illustrate a generalized MCD on categorical data and then show how our generalized MCD extends beyond categorical data to accommodate mixed data types (e.g., categorical, ordinal, and continuous). We illustrate this generalized MCD on data from two large scale projects: the Ontario Neurodegenerative Disease Research Initiative (ONDRI) and the Alzheimer's Disease Neuroimaging Initiative (ADNI) with data such as genetics (categorical), clinical instruments and surveys (categorical or ordinal), and neuroimaging (continuous) data. We also make R code and toy data available in order to illustrate our generalized MCD.},
  urldate = {2018-06-11TZ},
  journal = {bioRxiv},
  author = {Derek Beaton and Kelly M. Sunderland and Brian Levine and Jennifer Mandzia and Mario Masellis and Richard H. Swartz and Angela K. Troyer and Malcolm A. Binns and Herv{\a'e} Abdi and Stephen C. Strother},
  year = {2018},
  note = {},
}

@Article{rouder_theories_2018,
  title = {From theories to models to predictions: {A} {Bayesian} model comparison approach},
  volume = {85},
  issn = {0363-7751, 1479-5787},
  shorttitle = {From theories to models to predictions},
  url = {https://www.tandfonline.com/doi/full/10.1080/03637751.2017.1394581},
  doi = {10.1080/03637751.2017.1394581},
  language = {en},
  number = {1},
  urldate = {2018-05-25TZ},
  journal = {Communication Monographs},
  author = {Jeffrey N. Rouder and Julia M. Haaf and Frederik Aust},
  month = {jan},
  year = {2018},
  pages = {41--56},
  note = {},
}

@Article{jordan_focus_2018,
  title = {Focus on the {Target}: {The} {Role} of {Attentional} {Focus} in {Decisions} about {War}},
  shorttitle = {Focus on the {Target}},
  url = {https://osf.io/9fgu8/},
  doi = {10.17605/osf.io/9fgu8},
  abstract = {Legislative bodies have very important roles and understanding the psychology of their decision-making processes is a useful area of study. We add to this area by examining Congressional decision making when it comes to war measures and exploring where lawmakers' attention is focused when debating these issues. The present study hypothesized that legislators who support war measures focus more on other people and on the present circumstances. Speeches were obtained pertaining to the decisions for the U.S. to take military action in Kosovo, Iraq, and Libya. While we found mixed results depending on the circumstances of a specific conflict, we demonstrate how automated language analysis can be combined with voting records to better understand behavioral action, such as legislative decision.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Kayla Jordan and Erin Buchanan and William Padfield},
  year = {2018},
  note = {https://osf.io/r8qp2/},
}

@Article{stahl_false_2016,
  title = {False memory for perceptually similar but conceptually distinct line drawings},
  url = {https://psyarxiv.com/zr7m8/},
  doi = {10.17605/osf.io/zr7m8},
  abstract = {Whereas most false memory effects for pictorial material are thought to be based on semantic or conceptual similarity, some findings, based on novel visual material, have been attributed solely to perceptual similarity.  However, alternative accounts of these perceptual effects in terms of associative and/or conceptual processes have been proposed.  We report four experiments that address these points of criticism, using pairs of perceptually similar but conceptually distinct line drawings of objects (e.g., banana -- crescent). Similar lures were judged old more often than unrelated items, and confidence for false alarms was greater for similar lures than for unrelated items. This perceptual false memory effect was not modulated by rotation of stimuli between study and test, was unaffected by retention interval (0 vs. 20 min), and was obtained regardless of response format (old/new and old/similar/new). These findings rule out the criticism of previous perceptual false memory effects and more conclusively demonstrate false memory on the basis of perceptual similarity.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Christoph Stahl and Laura Henze and Frederik Aust},
  year = {2016},
  note = {https://osf.io/jxm7z/},
}

@Article{stahl_evaluative_2016,
  title = {Evaluative {Conditioning} with {Simultaneous} and {Sequential} {Pairings} {Under} {Incidental} and {Intentional} {Learning} {Conditions}},
  volume = {34},
  issn = {0278-016X},
  url = {http://guilfordjournals.com/doi/10.1521/soco.2016.34.5.382},
  doi = {10.1521/soco.2016.34.5.382},
  abstract = {Two studies investigated whether evaluative conditioning (EC) is modulated by pairing schedule (simultaneous vs. sequential) and by the nature of the orienting task. We tested the prediction that simultaneous (but not sequential) EC is obtained without awareness, and whether this modulatory effect supports dual-process theories of attitude acquisition. Results replicated the finding of a simultaneous EC effect in the absence of unconditioned stimulus (US) identity memory; in contrast, sequential EC effects depended on the presence of US identity memory. Yet, both EC effects were larger in the presence than in the absence of US identity memory and depended on the presence of US valence memory. Whereas the findings are consistent with dual learning processes, they can also be accounted for by a single learning process. Conceptual, theoretical, and methodological requirements for distinguishing between single- and dual-process models of EC are discussed.},
  number = {5},
  urldate = {2017-03-29TZ},
  journal = {Social Cognition},
  author = {Christoph Stahl and Tobias Heycke},
  year = {2016},
  pages = {382--412},
  note = {},
}

@Article{buchanan_english_2018,
  title = {English {Semantic} {Feature} {Production} {Norms}: {An} {Extended} {Database} of 4,436 {Concepts}},
  shorttitle = {English {Semantic} {Feature} {Production} {Norms}},
  url = {https://osf.io/gxbf4/},
  doi = {10.17605/osf.io/gxbf4},
  abstract = {The largest limiting factor in understanding memory and language networks is often the availability of normed stimuli to use and explore in experimental studies. In this study, we expand on three previous semantic feature overlap norms to over 4,000 cue stimuli ranging from nouns, verbs, adjectives, and other parts of speech. Participants in the norming study were asked to provide feature components of each cue stimuli, which were combined with the previous research using semantic feature production procedures. In addition to expanding previous research, this project explores different semantic overlap measurements by coding each word feature listed by root and affixes to determine different strengths of feature overlap. All information is provided in a searchable database for easy access and utilization for future researchers when designing experiments. The final database of cue-target pairs was paired with the Semantic Priming Project to examine the relation of feature overlap statistics on semantic priming in tandem with other psycholinguistic variables, such as association and thematics.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Erin Buchanan and Kathrene Valentine and Nicholas Maxwell},
  year = {2018},
  note = {https://osf.io/cjyzw/},
}

@Article{urry_effect_2018,
  title = {Effect of {Disgust} on {Judgments} of {Moral} {Wrongness}: {A} {Replication} of {Eskine}, {Kacinik}, and {Prinz} (2011)},
  url = {https://osf.io/fu384/},
  journal = {at Tufts University - Spring, 2017},
  author = {Heather L. Urry and Erin Sifre and Justin Song and Hannah Steinberg and Michelle Bornstein and Joan Kim and Martha Rimniceanu and Marissa Sashihara and Annie Artz and Kathy Chin and Eliza Flynn and Elim Na and Mel Andrews},
  month = {jan},
  year = {2018},
  note = {https://osf.io/ddmkm},
  keywords = {🔍No DOI found},
}

@Article{buchanan_does_2018,
  title = {Does the {Delivery} {Matter}? {Examining} {Randomization} at the {Item} {Level}},
  shorttitle = {Does the {Delivery} {Matter}?},
  url = {https://osf.io/p93df/},
  doi = {10.17605/osf.io/p93df},
  abstract = {Scales that are psychometrically sound, meaning those that meet established standards regarding reliability and validity when measuring one or more constructs of interest, are customarily evaluated based on a set modality (i.e., computer or paper) and administration (fixed-item order). Deviating from an established administration profile could result in non-equivalent response patterns, indicating the possible evaluation of a dissimilar construct. Randomizing item administration may alter or eliminate these effects. Therefore, we examined the differences in scale relationships for randomized and nonrandomized computer delivery for two scales measuring meaning/purpose in life. These scales have questions about suicidality, depression, and life goals that may cause item reactivity (i.e. a changed response to a second item based on the answer to the first item). Results indicated that item randomization does not alter scale psychometrics for meaning in life scales, which implies that results are comparable even if researchers implement different delivery modalities.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Erin Buchanan and Riley Foreman and Becca Johnson and Jeffrey Pavlacic and Rachel Swadley and Stefan Schulenberg},
  year = {2018},
  note = {https://osf.io/gvx7s/},
}

@Article{stahl_distorted_2015,
  title = {Distorted estimates of implicit and explicit learning in applications of the process-dissociation procedure to the {SRT} task},
  volume = {37},
  doi = {10.1016/j.concog.2015.08.003},
  journal = {Consciousness and Cognition},
  author = {Christoph Stahl and Marius Barth and Hilde Haider},
  year = {2015},
  pages = {27--43},
  note = {},
}

@Article{heino_bayesian_2018,
  title = {Bayesian evaluation of behavior change interventions: a brief introduction and a practical example},
  volume = {6},
  issn = {2164-2850},
  shorttitle = {Bayesian evaluation of behavior change interventions},
  url = {https://www.tandfonline.com/doi/full/10.1080/21642850.2018.1428102},
  doi = {10.1080/21642850.2018.1428102},
  language = {en},
  number = {1},
  urldate = {2018-05-25TZ},
  journal = {Health Psychology and Behavioral Medicine},
  author = {Matti T. J. Heino and Matti Vuorre and Nelli Hankonen},
  month = {jan},
  year = {2018},
  note = {https://zenodo.org/record/1209814\#.Wvy3H4jOVGM},
  pages = {49--78},
}

@Article{haaf_developing_2017,
  title = {Developing constraint in bayesian mixed models.},
  volume = {22},
  issn = {1939-1463, 1082-989X},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000156},
  doi = {10.1037/met0000156},
  language = {en},
  number = {4},
  urldate = {2018-05-25TZ},
  journal = {Psychological Methods},
  author = {Julia M. Haaf and Jeffrey N. Rouder},
  month = {dec},
  year = {2017},
  note = {https://github.com/PerceptionAndCognitionLab/ctx-indiff},
  pages = {779--798},
}

@Article{heyman_can_2018,
  title = {Can prediction-based distributional semantic models predict typicality?},
  doi = {10.17605/osf.io/59xtd},
  abstract = {Recent advances in the field of computational linguistics have led to the development of various prediction-based models of semantics. These models seek to infer word representations from large text collections by predicting target words from neighboring words (or vice versa). The resulting representations are vectors in a continuous space, collectively called word embeddings. Although psychological plausibility was not a primary concern for the developers of predictive models, it has been the topic of several recent studies in the field of psycholinguistics. That is, word embeddings have been linked to similarity ratings, word associations, semantic priming, word recognition latencies, etcetera. Here, we build on this work by investigating category structure. More specifically, we first obtained a prototype for a number of common categories (e.g., birds, fruit, vehicles,...) either  by averaging across exemplar vectors (e.g., robin, dove, sparrow,...) or by relying on the representation of the label itself (e.g., bird). Then, we correlated the cosine similarity between an exemplar and its prototype with human typicality judgments. The resulting correlations turned out to be disappointingly low, especially given the enthusiasm surrounding predictive models.},
  journal = {PsyArXiv},
  author = {Tom Heyman and Geert Heyman},
  year = {2018},
  note = {https://osf.io/nkfjy/},
}

@Article{buchanan_bulletproof_2018,
  title = {Bulletproof {Bias}? {Considering} the {Type} of {Data} in {Common} {Proportion} of {Variance} {Effect} {Sizes}},
  shorttitle = {Bulletproof {Bias}?},
  url = {https://osf.io/cs4vy/},
  doi = {10.17605/osf.io/cs4vy},
  abstract = {As effect sizes gain ground as important indicators of practical significance and as a meta-analytic tool, we must critically understand their limitations and biases. This project expands on research by @Okada2013, which highlighted the positive bias of eta squared and suggested the use of omega squared or epsilon for their lack of bias. These variance overlap measures were examined for potential bias in different data scenarios (i.e. truncated and Likert type data) to elucidate differences in bias from previous research. We found that data precision and truncation affected effect size bias, often lowering the bias in eta squared. This work expands our understanding of bias on variance overlap measures and allows researchers to make an informed choice about the type of effect to report given their research study. Implications for sample size planning and power are also discussed.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Erin Buchanan and John Scofield},
  year = {2018},
  note = {https://osf.io/urd8q/},
}

@Article{valentine_beyond_2018,
  title = {Beyond p-values: {Utilizing} {Multiple} {Estimates} to {Evaluate} {Evidence}},
  shorttitle = {Beyond p-values},
  url = {https://osf.io/9hp7y/},
  doi = {10.17605/osf.io/9hp7y},
  abstract = {Null hypothesis significance testing is frequently cited as a threat to the validity and reproducibility of the social sciences. While many individuals suggest we should focus on altering the *p*-value at which we deem an effect significant, we believe this suggestion is short-sighted. Alternative procedures (i.e., Bayesian analyses and Observation Oriented Modeling) can be more powerful and meaningful to our discipline. However, these methodologies are less frequently utilized and are rarely discussed in combination with NHST. Herein, we compare the possible interpretations of three analyses (ANOVA, Bayes Factor, and an Ordinal Pattern Analysis) in various data environments using a simulation study. The simulation generated 20000 unique datasets which varied sample size (*N*s of 10, 30, 100, 500, 1000), and effect sizes (*d*s of 0.10, 0.20, 0.05, 0.80). Through this simulation, we find that changing the threshold at which *p*-values are considered significant has little to no effect on conclusions. Further, we find that evaluating multiple estimates as evidence of an effect can allow for a more robust and nuanced report of findings. These findings suggest the need to redefine evidentiary value and reporting practices.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Kathrene Valentine and Erin Buchanan and John Scofield and Marshall Beauchamp},
  year = {2018},
  note = {https://osf.io/u9hf4/},
}

@Article{buchanan_extension_2018,
  title = {An {Extension} of the {QWERTY} {Effect}: {Not} {Just} the {Right} {Hand}, {Expertise} and {Typability} {Predict} {Valence} {Ratings} of {Words}},
  shorttitle = {An {Extension} of the {QWERTY} {Effect}},
  url = {https://osf.io/k7dx5/},
  doi = {10.31219/osf.io/k7dx5},
  abstract = {Typing is a ubiquitous daily action for many individuals; yet, research on how these actions have changed our perception of language is limited. The QWERTY effect is an increase in valence ratings for words typed more with the right hand on a traditional keyboard (Jasmin \& Casasanto, 2012). Although this finding is intuitively appealing given both right handed dominance and the smaller number of letters typed with the right hand, extension and replication of the right side advantage is warranted. The present paper reexamined the QWERTY effect within the embodied cognition framework (Barsalou, 1999) and found that the right side advantage is replicable to new valence stimuli, as well as experimental manipulation. Further, when examining expertise, right side advantage interacted with typing speed and typability (i.e., alternating hand keypresses or finger switches) portraying that both skill and our procedural actions play a role in judgment of valence on words.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Erin Buchanan and Kathrene Valentine},
  year = {2018},
  note = {https://osf.io/zs2qj/},
}

@Article{derringer_simple_2018,
  title = {A simple correction for non-independent tests},
  url = {https://psyarxiv.com/f2tyw/},
  doi = {10/gdrbxc},
  abstract = {Psychologists wrestle with how to best handle multiple comparisons, while maintaining a balance between false positives and false negatives. Undercorrection, such as ignoring the presence of multiple comparisons altogether, is known to yield an unacceptably high rate of false positives. Overcorrection, such as treating all tests as independent when they are not, results in overly conservative evaluations of statistical significance. This tutorial demonstrates \$M\_\{eff\}\$ correction, a method for adjusting statistical significance thresholds for multiple comparisons, without the assumption of independence of tests. This method, in which the effective number of tests (\$M\_\{eff\}\$) is estimated from the correlations among the variables being tested, was developed and validated in the field of genetics, but is based on statistical concepts (eigenvalues) that are very familiar to psychologists. \$M\_\{eff\}\$ correction can be applied in psychological research to balance the necessity of correction for multiple comparisons with the concerns that arise from complex, correlated tests.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Jaime Derringer},
  year = {2018},
  note = {https://osf.io/re5w2/},
}

@Article{pavlacic_meta-analysis_2018,
  title = {A {Meta}-{Analysis} of {Expressive} {Writing} on {Positive} {Psychology} {Variables} and {Traumatic} {Stress}},
  url = {https://osf.io/u98cw/},
  doi = {10.17605/osf.io/u98cw},
  abstract = {Emotional expression has been shown to be benficial for promoting both positive psychological and physical health outcomes. Unfortunately, inhibiting emotions can lead to impairments in physical and psychological health. James Pennebaker showed that expressive writing is an effective form of emotional expression, and he and others have used expressive writing as an experimental manipulation to gauge its effectiveness in treating a wide variety of health-related and psychological outcomes. While many studies have been conducted that examine the effectiveness of expressive writing across such outcomes, a considerable amount of these studies tend to neglect necessary considerations such as power and meaningfulness of respective effect sizes. Four previous meta-analyses have been conducted that examine expressive writing's affect on psychological outcomes, however, these studies focus on the experimental versus control group effect size. Thus, our meta-analysis sought to examine the effectiveness of an expressive writing intervention on only the experimental conditions in studies measuring posttraumatic growth, posttraumatic stress, and quality of life using random effects models. Results indicated a small overall effect size for posttraumatic stress and negligible to small effect sizes for posttraumatic growth and quality of life. Implications for future research design and interpretation of published research are discussed.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Jeffrey Pavlacic and Erin Buchanan and Nicholas Maxwell and Tabetha Hopke and Stefan Schulenberg},
  year = {2018},
  note = {https://osf.io/4mjqt/},
}

@Article{hardwicke_mapping_2018,
  title = {Mapping the {Universe} of {Registered} {Reports}},
  url = {https://osf.io/preprints/bitss/fzpcy/},
  doi = {10.31222/osf.io/fzpcy},
  abstract = {Selection pressures for significant results may infuse bias into the research process. We evaluated the implementation of one innovation designed to mitigate this bias, ‘Registered Reports’, where study protocols are peer-reviewed and granted in-principle acceptance (IPA) for publication before the study has been conducted. As of February 2018, 91 journals had adopted Registered Reports and 91 Final Reports had been published. Psychology journals are the principal adopters, but expansion has begun into medicine, social science, and other fields. Among 29 journals that responded to a survey, 334 protocols had been submitted to them, 87 had been granted IPA and 32 Final Reports had been published or were in press as of July 2017. We encountered several sub-optimal implementation practices, including non-availability of IPA protocols, and diverse approaches to protocol registration in the absence of a single central registry. Registered Reports should be iteratively evaluated and improved to ensure maximal benefits.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Tom Hardwicke and john Ioannidis},
  year = {2018},
  note = {https://osf.io/7dpwb/},
}

@Article{stevens_predicting_2018,
  title = {Predicting similarity judgments in intertemporal choice with machine learning},
  volume = {25},
  issn = {1069-9384, 1531-5320},
  url = {http://link.springer.com/10.3758/s13423-017-1398-1},
  doi = {10/gdfghk},
  language = {en},
  number = {2},
  urldate = {2018-07-08TZ},
  journal = {Psychonomic Bulletin \& Review},
  author = {Jeffrey R. Stevens and Leen-Kiat Soh},
  month = {apr},
  year = {2018},
  note = {},
  pages = {627--635},
}
